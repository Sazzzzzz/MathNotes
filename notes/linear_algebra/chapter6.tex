%!TEX root = main.tex
\chapter{内积空间}
\section{内积与范数}

自然的，定义范数时，我们考虑\(\R^{n} \) 中的长度：\[
    \abs{x} = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}
\]
为使该定义在复数域上有定义，我们将平方改为模的平方：
\begin{align*}
    \abs{x} &= \sqrt{\abs{x_1}^2 + \abs{x_2}^2 + \cdots + \abs{x_n}^2}
    &= \sqrt{x_1 \conj{x_1} + x_2 \conj{x_2} + \cdots + x_n
    \conj{x_n}}
\end{align*}

于是我们如此定义内积：
\begin{definition}[内积]
    设\(V\)为域\(\F\)上的线性空间，则称映射
    \[
        \inner{\cdot}{\cdot} : V \times V \to \F
    \]
    为\(V\)上的一个\textbf{内积}，如果对任意\(x,y,z \in V, a \in \F\)，满足：
    \begin{itemize}
        \item (正定性) \(\inner{x}{x} \geq 0\)，且当且仅当\(x = 0\)时取等号
        \item (第一个位置的线性性) \(\inner{ax + y}{z} = a\inner{x}{z} + \inner{y}{z}\)
        \item (共轭对称性) \(\inner{x}{y} = \conj{\inner{y}{x}}\)
    \end{itemize}
\end{definition}

这样得到的内积称为厄米特内积(Hermitian inner product)，共轭对称性可导出\[
    \inner{x}{\lambda y} = \conj{\lambda} \inner{x}{y}
\]

\begin{definition}[范数]
    \[
        \norm{x} = \sqrt{\inner{x}{x}}
    \]
\end{definition}

\begin{theorem}[勾股定理]
    \(\norm{u}^{2} + \norm{v}^{2} = \norm{u+v}^{2} \iff \inner{u}{v} = 0\)
\end{theorem}

考虑向量\(u\) 在向量\(v\) 上的正交分解：
设\(u = cv + (u-cv)\) ，则由正交应有：
\begin{align*}
    0 &= \inner{u-cv}{v} = \inner{u}{v} - c\norm{v}^{2} \\
    c &= \frac{\inner{u}{v}}{\norm{v}^{2}}
\end{align*}
故\[
    u = \frac{\inner{u}{v}}{\norm{v}^{2}} v + \left(u -
    \frac{\inner{u}{v}}{\norm{v}^{2}} v\right)
\]

对于任意\(u\) ，\(v\) ，由勾股定理：
\begin{align*}
    \norm{u}^{2} &= \norm{u - \frac{\inner{u}{v}}{\norm{v}^{2}} v}^{2} +
    \norm{\frac{\inner{u}{v}}{\norm{v}^{2}} v}^{2} \\
    &\geq \frac{\abs{\inner{u}{v}}^{2}}{\norm{v}^{2}}
\end{align*}

也就是柯西不等式：
\begin{theorem}[柯西不等式]
    \(\abs{\inner{u}{v}} \leq \norm{u} \norm{v}\)
\end{theorem}

\begin{corollary}
    \textbf{平行四边形法则}： \(\norm{u + v}^{2} + \norm{u - v}^{2} = 2\norm{u}^{2} +
    2\norm{v}^{2}\)

    实数域中满足极化恒等式：\(\inner{u}{v} = \frac{1}{4}(\norm{u+v}^{2} -
    \norm{u-v}^{2})\)

    但复数域中我们有
    \begin{align*}
        \inner{u}{v} + \conj{\inner{u}{v}} &= \frac{1}{2}(\norm{u+v}^{2} -
        \norm{u-v}^{2}) \\
        \inner{u}{\i v} + \conj{\inner{u}{\i v}} &=
        \frac{1}{2}(\norm{u+\i v}^{2} -
        \norm{u-\i v}^{2})
    \end{align*}
    从而：
    \[
        \inner{u}{v} = \frac{1}{4}(\norm{u+v}^{2} - \norm{u-v}^{2}) +
        \frac{\i}{4}(\norm{u+\i v}^{2} + \norm{u-\i v}^{2})
    \]
    常用的还有另一种形式：
    \begin{align*}
        \inner{Tu}{v} &= \frac{1}{4}(\inner{T(u+v)}{u+v} -
        \inner{T(u-v)}{u-v}) \\
        &\quad + \frac{\i}{4}(\inner{T(u+\i v)}{u+\i v} -
        \inner{T(u-\i v)}{u-\i v})
    \end{align*}
\end{corollary}

\section{规范正交基}

\begin{definition}[规范正交组与规范正交基]
    设\(V\)为域\(\F\)上的线性空间，\(\{e_1, e_2, \cdots, e_m\}\)为\(V\)的一组向量，
    如果对任意\(i\)，\(j\) ，有：
    \[
        \inner{e_i}{e_j} =
        \begin{cases}
            1 & i = j \\
            0 & i \neq j
        \end{cases}
    \]
    则称该组向量为\(V\)上的一组\textbf{规范正交组}，如果该组向量还是\(V\)的一组基，
    则称该组向量为\(V\)上的一组\textbf{规范正交基}。
\end{definition}

由于任意一组线性无关向量都可以扩充为一组基，故任何一个规范向量组也能扩充为一组规范正交基。

\begin{corollary}
    设\(\{e_1, e_2, \cdots, e_m\}\)为\(V\)上的一组规范正交组，则：\[
        \norm{a_1 e_1 + a_2 e_2 + \cdots + a_m e_m}^{2} =
        \abs{a_1}^{2} + \abs{a_2}^{2} + \cdots + \abs{a_m}^{2}
    \]
\end{corollary}

\begin{theorem}[Bessel不等式]
    设\(\{e_1, e_2, \cdots, e_m\}\)为\(V\)上的一组规范正交组，则对任意\(v \in V\)，有：
    \[
        \norm{v}^{2} \geq \abs{\inner{v}{e_1}}^{2} +
        \abs{\inner{v}{e_2}}^{2} + \cdots + \abs{\inner{v}{e_m}}^{2}
    \]
    等号成立的充分必要条件是\(v\)在\(e_1, e_2, \cdots, e_m\)张成的子空间中。
\end{theorem}

\begin{proof}
    设\(u = \inner{v}{e_1} e_1 + \inner{v}{e_2} e_2 + \cdots +
    \inner{v}{e_m} e_m\)，对于任意\(e_{k}\)，有\(\inner{v-u}{e_k} = 0\)，
    故\[
        \inner{v-u}{u} = 0
    \]
    则由勾股定理：
    \[
        \norm{v}^{2} = \norm{v-u}^{2} + \norm{u}^{2} \geq
        \norm{u}^{2} = \abs{\inner{v}{e_1}}^{2} +
        \abs{\inner{v}{e_2}}^{2} + \cdots + \abs{\inner{v}{e_m}}^{2}
    \]
    等号成立的充分必要条件是\(v-u = 0\)，即\(v\)在\(e_1, e_2, \cdots, e_m\)张成的子空间中。
\end{proof}

\begin{corollary}[向量的规范正交基表示]
    设\(\{e_1, e_2, \cdots, e_n\}\)为\(V\)的一组规范正交基，则对任意\(v \in V\)，有
    \begin{itemize}
        \item \(v = \inner{v}{e_1} e_1 + \inner{v}{e_2} e_2 + \cdots +
            \inner{v}{e_n} e_n\)
        \item \(\norm{v}^{2} = \abs{\inner{v}{e_1}}^{2} +
            \abs{\inner{v}{e_2}} ^{2} + \cdots + \abs{\inner{v}{e_n}}^{2}\)
        \item \(\inner{u}{v} = \inner{u}{e_1} \conj{\inner{v}{e_1}} +
                \inner{u}{e_2} \conj{\inner{v}{e_2}} + \cdots + \inner{u}{e_n}
            \conj{\inner{v}{e_n}}\) （Parseval 恒等式）
    \end{itemize}
\end{corollary}

这里出现的Parseval恒等式与Bessel不等式与傅立叶级数中的Parseval恒等式与Bessel不等式是类似的。
\begin{note}
    \(f\) 的傅立叶级数展开系数有Bessel不等式：
    \[
        \frac{a_{0}^{2}}{2} + \sum_{n=1}^{\infty} (a_n^2 + b_n^2) \leq
        \frac{1}{\pi} \int_{-\pi}^{\pi} f (x)^{2} \d{x}
    \]
    若\(f\) 的傅立叶级数一致收敛于\(f\)，则等号成立。（Parseval恒等式）
\end{note}

\begin{theorem}[Gram-Schimidt 正交化]
    设\(V\)为域\(\F\)上的线性空间，\(\{v_1, v_2, \cdots, v_n\}\)为\(V\)的一组线性无关向量，
    令\(f_{1}= v_{1}\)，\(f_{k}\) 依次定义为：
    \[
        f_k = v_k - \sum_{i=1}^{k-1} \frac{\inner{v_k}{f_i}}{\norm{f_i}^{2}} f_i
    \]
    再令\(e_k = \frac{f_k}{\norm{f_k}}\)，则\(\{e_1, e_2, \cdots,
    e_n\}\)为\(V\)的一组规范正交组。
    \[
        \Span(v_1, v_2, \cdots, v_k) = \Span(e_1, e_2, \cdots, e_k)
    \]
\end{theorem}

Gram-Schimidt 正交化过程是对新向量反复移除旧向量在其上的分量的过程。

\begin{proof}
    用数学归纳法证明，\(k=1\)时显然成立，假设对\(j\leq k\)时成立，则：
    \begin{align*}
        \inner{e_{k}}{e_{j}} &= \frac{1}{\norm{f_k} \norm{f_j}}
        \inner{f_k}{f_j} \\
        &= \frac{1}{\norm{f_k} \norm{f_j}} \inner{v_k -
        \sum_{i=1}^{k-1} \frac{\inner{v_k}{f_i}}{\norm{f_i}^{2}} f_i}{f_j} \\
        &= \frac{1}{\norm{f_k} \norm{f_j}} \left(
        \inner{v_{k}}{f_{j}} - \inner{v_{k}}{f_{j}} \right) \\
        &= 0
    \end{align*}
    故\(\{e_1, e_2, \cdots, e_n\}\)为\(V\)的一组规范正交组。又由于该组与原向量组维数相同，
    故该组为\(V\)的一组规范正交基。
\end{proof}

% todo: 舒尔定理

\subsection{内积空间上的线性泛函}

\begin{theorem}[Rietz表示定理]
    设\(V\)为域\(\F\)上的内积空间，则对任意线性泛函\(f \in V'\)，存在唯一的向量\(y \in V\)，
    使得对任意\(x \in V\)，有：
    \[
        \varphi(x) = \inner{x}{y}
    \]
    即映射\(y \mapsto f\)为从\(V\)到\(V'\)的共轭线性同构。
\end{theorem}

\begin{proof}
    有限维情形下：
    \begin{align*}
        \varphi(x) &= \varphi\left(\inner{x}{e_1}e_{1} + \dots +
        \inner{x}{e_n}e_{n}\right) \\
        &= \inner{x}{e_1}\varphi(e_1) + \dots + \inner{x}{e_n}\varphi(e_n) \\
        &= \inner{x}{\conj{\varphi(e_1)} e_1 + \dots +
        \conj{\varphi(e_n)} e_n}
    \end{align*}
    从而\(y = \conj{\varphi(e_1)} e_1 + \dots +
    \conj{\varphi(e_n)} e_n\)

    无限维希尔伯特空间情形下：若\(\varphi = 0\)，则取\(y = 0\)即可。
    否则，令\(K = \nullspace f\)，存在\(z \in K^\perp \)使\(f(z) = k \neq 0\)。

    \(\forall x \in V\)，注意到：
    \[
        \varphi(x-\frac{1}{k} \varphi(x)z) = \varphi(x) - \frac{1}{k}
        \varphi(x) \varphi(z) =0
    \]
    故\(x - \frac{1}{k} \varphi(x) z \in K\)，从而：\[
        \inner{x-\frac{1}{k}\varphi(x)z}{z} = 0,
    \]
    即\(\varphi(x) = \inner{x}{\frac{kz}{\norm{z}^{2}}}\)
\end{proof}

\section{正交补与最小化问题}
% TODO:为什么伪逆顺便把有解时解的范数也最小化了？
% TODO:尝试一下正交化多项式并最优化sin x
\subsection{正交补}

正交补这个概念在泛函分析中其实已经讲的很清楚了。在有限维的情况下，泛函分析中难证明的结论可以变得很简单。

\begin{definition}[正交补]
    设\(U\)是\(V\)的子空间，\(U\)的\textbf{正交补}（orthogonal complement）定义为：
    \[
        U^\perp = \{v \in V : \forall u \in U, \inner{v}{u} = 0\}
    \]
\end{definition}

\begin{theorem}
    设\(U\)是\(V\)的有限维子空间，则
    \[
        V = U \oplus U^\perp
    \]
\end{theorem}

\begin{proof}
    设\(\{e_1, \dots, e_m\}\)是\(U\)的一组规范正交基。对于任意\(v \in V\)，我们可以将其分解为：
    \[
        v = \underbrace{\sum_{i=1}^m \inner{v}{e_i} e_i}_{u} +
        \underbrace{\left( v - \sum_{i=1}^m \inner{v}{e_i} e_i \right)}_{w}
    \]
    显然\(u \in U\)。对于任意\(j \in \{1, \dots, m\}\)，
    \[
        \inner{w}{e_j} = \inner{v}{e_j} - \sum_{i=1}^m \inner{v}{e_i}
        \inner{e_i}{e_j} = \inner{v}{e_j} - \inner{v}{e_j} = 0
    \]
    故\(w\)与\(U\)的基向量正交，从而\(w \in U^\perp\)。
    这就证明了\(V = U + U^\perp\)。

    若\(v \in U \cap U^\perp\)，则\(\inner{v}{v} = 0 \implies v = 0\)，故和是直和。
\end{proof}

\begin{corollary}
    \[
        \dim U^\perp = \dim V - \dim U
    \]
\end{corollary}

可以把正交补看作是商空间的一个可视化版本，正交补的维数等于商空间的维数。

\begin{definition}[正交投影]
    对于任意\(v \in V\)，存在唯一的\(u \in U\)和\(w \in U^\perp\)使得\(v = u + w\)。
    定义\textbf{正交投影}算子\(P_U\)为：
    \[
        P_U v = u
    \]
\end{definition}

在泛函分析中，正交投影通常定义为空间到子空间的最佳逼近，虽然定义不同，但本质是一样的。

\begin{theorem}[正交投影的性质]
    设\(P_U\)是\(V\)到\(U\)的正交投影，则：
    \begin{itemize}
        \item \(\range P_U = U\)
        \item \(\nullspace P_U = U^\perp\)
        \item 对任意\(v \in V\)，\(\norm{P_U v} \leq \norm{v}\)
        \item 若\(\{e_1, \dots, e_m\}\)是\(U\)的规范正交基，则
            \[
                P_U v = \sum_{i=1}^m \inner{v}{e_i} e_i
            \]
    \end{itemize}
\end{theorem}

在泛函分析中投影算子是压缩映射的证明是需要一定技巧的，但在有限维空间中可以直接用勾股定理证明\UseVerb{smile}。
注意到投影的代数表示只与子空间\(U\)的规范正交基有关，而与整个空间\(V\)的基无关。

\subsection{最小化问题}

最小化问题实际上是用勾股定理证明了正交投影与最佳逼近定义的等价性。投影点就是子空间中距离原向量最近的点。

\begin{theorem}[最佳逼近]
    设\(U\)是\(V\)的子空间，\(v \in V\)，则
    \[
        \norm{v - P_U v} \leq \norm{v - u}
    \]
    对任意\(u \in U\)成立。等号成立当且仅当\(u = P_U v\)。
\end{theorem}

\begin{proof}
    \begin{align*}
        \norm{v - u}^2 &= \norm{(v - P_U v) + (P_U v - u)}^2 \\
        &= \norm{v - P_U v}^2 + \norm{P_U v - u}^2 \quad (\text{勾股定理，
        因为 } v - P_U v \in U^\perp, P_U v - u \in U) \\
        &\geq \norm{v - P_U v}^2
    \end{align*}
    等号成立当且仅当\(\norm{P_U v - u} = 0\)，即\(u = P_U v\)。
\end{proof}

\subsection{伪逆}

在初学伪逆（Pseudoinverse）时，这个定义显得非常神秘。因为对于有解的线性方程，它能给出范数最小的解；对于无解的线性方程，
它可以给出最佳逼近，也就是误差最小的解。但实际上，伪逆的定义是很简单的。

这里的思路其实类似于商空间。线性映射基本定理告诉我们，结合上面的维数定理，零空间的正交补和值域应当有相同的维数。相当于把整个空间用零空间给分成了若干份。

\begin{theorem}
    设\(T \in \L(V, W)\)，则限制映射
    \[
        T|_{(\nullspace T)^\perp} : (\nullspace T)^\perp \to \range T
    \]
    是双射（既单又满）。
\end{theorem}

\begin{proof}
    设\(v \in (\nullspace T)^\perp\)且\(Tv = 0\)，则\(v \in \nullspace T\)。
    故\(v \in (\nullspace T)^\perp \cap \nullspace T = \{0\}\)，所以是单射。

    对于任意\(y \in \range T\)，存在\(v \in V\)使得\(Tv = y\)。
    将\(v\)分解为\(v = u + w\)，其中\(u \in \nullspace T\)，\(w \in
    (\nullspace T)^\perp\)。
    则\(Tv = Tu + Tw = 0 + Tw = Tw = y\)。
    故\(w\)是\((\nullspace T)^\perp\)中映射到\(y\)的元素，所以是满射。
\end{proof}

伪逆的定义其实也很有意思，它是先人为的把任何一个在映射空间中的向量投影到值域上，然后用限制过后的既是单射又是满射的线性映射，返回到定义域上。

\begin{definition}[伪逆]
    设\(T \in \L(V, W)\)，\(T\)的\textbf{伪逆} \(T^\dagger \in \L(W, V)\) 定义为：
    \[
        T^\dagger y = (T|_{(\nullspace T)^\perp})^{-1} (P_{\range T} y)
    \]
    其中\(P_{\range T}\)是\(W\)到\(\range T\)的正交投影。
\end{definition}

\begin{theorem}[伪逆的性质]
    对于线性方程 \(Tx = y\)：
    \begin{itemize}
        \item 若方程无解，\(x = T^\dagger y\) 给出\textbf{最佳近似解}，即
            \(\norm{Tx - y}\) 最小。
        \item 若方程有解（可能有无穷多解），\(x = T^\dagger y\) 给出\textbf{最小范数解}，
            即在所有解中 \(\norm{x}\) 最小。
    \end{itemize}
\end{theorem}

\begin{proof}
    对于任意\(x \in V\)，
    \[
        \norm{Tx - y} \geq \norm{P_{\range T} y - y}
    \]
    等号成立当且仅当 \(Tx = P_{\range T} y\)。
    令 \(x_0 = T^\dagger y \in (\nullspace T)^\perp\)，则 \(T x_0 =
    P_{\range T} y\)，故 \(x_0\) 是最佳近似解之一。

    若 \(x\) 是另一个满足 \(Tx = P_{\range T} y\) 的解，则 \(T(x - x_0) = 0\)，即
    \(x - x_0 \in \nullspace T\)。
    由于 \(x_0 \in (\nullspace T)^\perp\)，由勾股定理：
    \[
        \norm{x}^2 = \norm{x_0 + (x - x_0)}^2 = \norm{x_0}^2 +
        \norm{x - x_0}^2 \geq \norm{x_0}^2
    \]
    故 \(x_0\) 是范数最小的。
\end{proof}

在这里不难看到，伪逆的定义其实并不那么依赖于有限维空间，在无穷维空间上也可以一定程度的定义伪逆。

% TODO: 为什么要定义内积
% https://www.zhihu.com/question/26959321/answer/1983367204813697959
